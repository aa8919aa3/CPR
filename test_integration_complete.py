#!/usr/bin/env python3
"""
å®Œæ•´é›†æˆæ¸¬è©¦ - é©—è­‰æ–°çš„æ•¸é‡ç´šçœ¾æ•¸é è™•ç†æ–¹æ³•åœ¨æ•´å€‹ç³»çµ±ä¸­çš„é›†æˆ
"""

import numpy as np
import pandas as pd
import tempfile
import os
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from cpr.main_processor_optimized import EnhancedJosephsonProcessor
from cpr.josephson_model import preprocess_data_numba, preprocess_data_fallback

def create_test_csv(filename, x_data, y_data):
    """å‰µå»ºæ¸¬è©¦ç”¨çš„ CSV æª”æ¡ˆ"""
    df = pd.DataFrame({
        'y_field': x_data,  # External magnetic flux
        'Ic': y_data        # Supercurrent
    })
    df.to_csv(filename, index=False)
    return filename

def test_complete_integration():
    """æ¸¬è©¦å®Œæ•´çš„ç³»çµ±é›†æˆ"""
    print("=" * 60)
    print("å®Œæ•´é›†æˆæ¸¬è©¦ - æ•¸é‡ç´šçœ¾æ•¸é è™•ç†æ–¹æ³•")
    print("=" * 60)
    
    # å‰µå»ºå…·æœ‰ä¸åŒæ•¸é‡ç´šçš„æ¸¬è©¦æ•¸æ“š
    np.random.seed(42)
    n_points = 100
    
    # æ¸¬è©¦æ¡ˆä¾‹ 1: æ­£å¸¸æ•¸æ“š
    x_data1 = np.linspace(0, 10, n_points)
    y_data1 = 2.5 * np.sin(2 * np.pi * 0.8 * x_data1) + 0.1 * x_data1 + 1.2 + 0.1 * np.random.normal(0, 1, n_points)
    
    # æ¸¬è©¦æ¡ˆä¾‹ 2: å¤§æ•¸é‡ç´šå·®ç•°çš„æ•¸æ“š
    x_data2 = np.linspace(0, 1e-3, n_points)  # å¾®å°ç¯„åœ
    y_data2 = 1e6 * np.sin(2 * np.pi * 500 * x_data2) + 1e5 + 1e4 * np.random.normal(0, 1, n_points)  # å¤§æ•¸å€¼
    
    # æ¸¬è©¦æ¡ˆä¾‹ 3: æ··åˆæ•¸é‡ç´šæ•¸æ“š
    x_data3 = np.concatenate([
        np.linspace(0, 1e-6, n_points//3),
        np.linspace(1e-3, 1e-2, n_points//3),
        np.linspace(1, 10, n_points//3)
    ])
    y_data3 = np.concatenate([
        1e9 * np.sin(2 * np.pi * 1e3 * x_data3[:n_points//3]) + 1e8,
        1e3 * np.sin(2 * np.pi * 10 * x_data3[n_points//3:2*n_points//3]) + 1e2,
        10 * np.sin(2 * np.pi * 0.5 * x_data3[2*n_points//3:]) + 5
    ])
    
    test_cases = [
        ("normal_data", x_data1, y_data1),
        ("large_scale_diff", x_data2, y_data2),
        ("mixed_scales", x_data3, y_data3)
    ]
    
    with tempfile.TemporaryDirectory() as temp_dir:
        print(f"ä½¿ç”¨è‡¨æ™‚ç›®éŒ„: {temp_dir}")
        
        # å‰µå»ºæ¸¬è©¦æª”æ¡ˆ
        csv_files = []
        for name, x_data, y_data in test_cases:
            csv_file = create_test_csv(
                os.path.join(temp_dir, f"{name}.csv"),
                x_data, y_data
            )
            csv_files.append(csv_file)
            print(f"âœ“ å‰µå»ºæ¸¬è©¦æª”æ¡ˆ: {name}.csv")
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        output_dir = os.path.join(temp_dir, "output")
        os.makedirs(output_dir, exist_ok=True)
        
        print("\n" + "=" * 40)
        print("æ¸¬è©¦é è™•ç†æ–¹æ³•æ¯”è¼ƒ")
        print("=" * 40)
        
        # ç›´æ¥æ¸¬è©¦é è™•ç†æ–¹æ³•
        for name, x_data, y_data in test_cases:
            print(f"\næ¸¬è©¦æ¡ˆä¾‹: {name}")
            print("-" * 30)
            
            # ä½¿ç”¨æ–°çš„æ•¸é‡ç´šçœ¾æ•¸æ–¹æ³•
            try:
                x_norm_new, y_norm_new, x_factor_new, y_factor_new = preprocess_data_numba(x_data, y_data)
                print(f"æ–°æ–¹æ³• - x_factor: {x_factor_new:.2e}, y_factor: {y_factor_new:.2e}")
                print(f"æ–°æ–¹æ³• - xæ­¸ä¸€åŒ–ç¯„åœ: [{np.min(x_norm_new):.2e}, {np.max(x_norm_new):.2e}]")
                print(f"æ–°æ–¹æ³• - yæ­¸ä¸€åŒ–ç¯„åœ: [{np.min(y_norm_new):.2e}, {np.max(y_norm_new):.2e}]")
            except Exception as e:
                print(f"æ–°æ–¹æ³•å¤±æ•—: {e}")
                continue
            
            # ä½¿ç”¨å›é€€æ–¹æ³•æ¯”è¼ƒ
            try:
                x_norm_old, y_norm_old, x_factor_old, y_factor_old = preprocess_data_fallback(x_data, y_data)
                print(f"èˆŠæ–¹æ³• - x_factor: {x_factor_old:.2e}, y_factor: {y_factor_old:.2e}")
                print(f"èˆŠæ–¹æ³• - xæ­¸ä¸€åŒ–ç¯„åœ: [{np.min(x_norm_old):.2e}, {np.max(x_norm_old):.2e}]")
                print(f"èˆŠæ–¹æ³• - yæ­¸ä¸€åŒ–ç¯„åœ: [{np.min(y_norm_old):.2e}, {np.max(y_norm_old):.2e}]")
                
                # è¨ˆç®—æ”¹é€²æ¯”ç‡
                x_improvement = x_factor_new / x_factor_old if x_factor_old != 0 else float('inf')
                y_improvement = y_factor_new / y_factor_old if y_factor_old != 0 else float('inf')
                print(f"æ”¹é€²æ¯”ç‡ - xæ–¹å‘: {x_improvement:.2f}, yæ–¹å‘: {y_improvement:.2f}")
                
            except Exception as e:
                print(f"èˆŠæ–¹æ³•å¤±æ•—: {e}")
        
        print("\n" + "=" * 40)
        print("æ¸¬è©¦å®Œæ•´ç³»çµ±é›†æˆ")
        print("=" * 40)
        
        # åˆå§‹åŒ–è™•ç†å™¨
        processor = EnhancedJosephsonProcessor()
        
        # è™•ç†æ‰€æœ‰æ¸¬è©¦æª”æ¡ˆ
        results = processor.process_files(csv_files, output_dir)
        
        print(f"\nè™•ç†çµæœ:")
        print(f"ç¸½è¨ˆæª”æ¡ˆ: {len(results)}")
        successful = sum(1 for r in results if r['success'])
        failed = len(results) - successful
        print(f"æˆåŠŸ: {successful}")
        print(f"å¤±æ•—: {failed}")
        
        # æª¢æŸ¥è¼¸å‡ºæª”æ¡ˆ
        print(f"\nç”Ÿæˆçš„æª”æ¡ˆ:")
        for result in results:
            if result['success']:
                dataid = result['dataid']
                expected_files = [
                    f"{dataid}_fitted_curve_normalized_plot.png",
                    f"{dataid}_fitted_curve_plot.png",
                    f"{dataid}_residuals_plot.png",
                    f"{dataid}_phase_folded_with_drift.png",
                    f"{dataid}_cycles_colored_matplotlib.png"
                ]
                
                print(f"\n{dataid}:")
                for filename in expected_files:
                    filepath = os.path.join(output_dir, filename)
                    if os.path.exists(filepath):
                        size = os.path.getsize(filepath)
                        print(f"  âœ“ {filename} ({size} bytes)")
                    else:
                        print(f"  âœ— {filename} (missing)")
                
                # é¡¯ç¤ºæ“¬åˆåƒæ•¸
                params = ['I_c', 'phi_0', 'f', 'T', 'r', 'C']
                param_str = ", ".join([f"{p}: {result.get(p, 'N/A'):.2e}" if isinstance(result.get(p), (int, float)) 
                                     else f"{p}: {result.get(p, 'N/A')}" for p in params])
                print(f"  åƒæ•¸: {param_str}")
                print(f"  RÂ²: {result.get('r_squared', 'N/A'):.4f}")
            else:
                print(f"\n{result['dataid']}: å¤±æ•— - {result.get('error', 'Unknown error')}")
        
        # æª¢æŸ¥åˆ†ææ‘˜è¦æª”æ¡ˆ
        summary_file = os.path.join(output_dir, 'analysis_summary.csv')
        if os.path.exists(summary_file):
            print(f"\nâœ“ åˆ†ææ‘˜è¦æª”æ¡ˆå·²å‰µå»º: analysis_summary.csv")
            summary_df = pd.read_csv(summary_file)
            print(f"æ‘˜è¦åŒ…å« {len(summary_df)} æ¢è¨˜éŒ„")
        else:
            print(f"\nâœ— åˆ†ææ‘˜è¦æª”æ¡ˆæœªæ‰¾åˆ°")
        
        print("\n" + "=" * 60)
        print("é›†æˆæ¸¬è©¦å®Œæˆ!")
        print("=" * 60)
        
        return results

if __name__ == "__main__":
    results = test_complete_integration()
    
    # ç°¡å–®çš„æˆåŠŸ/å¤±æ•—çµ±è¨ˆ
    successful = sum(1 for r in results if r['success'])
    total = len(results)
    
    print(f"\næœ€çµ‚çµæœ: {successful}/{total} æª”æ¡ˆè™•ç†æˆåŠŸ")
    
    if successful == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼æ–°çš„æ•¸é‡ç´šçœ¾æ•¸é è™•ç†æ–¹æ³•å·²æˆåŠŸé›†æˆåˆ°æ•´å€‹ç³»çµ±ä¸­ã€‚")
        sys.exit(0)
    else:
        print("âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦é€²ä¸€æ­¥èª¿æŸ¥ã€‚")
        sys.exit(1)
