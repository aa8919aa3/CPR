#!/usr/bin/env python3
"""
ç”Ÿæˆç‰¹å®šæ–‡ä»¶çš„æ·±åº¦åˆ†æå ±å‘Š
é‡å°æ–‡ä»¶ ID: 386, 381, 418, 397, 394, 416, 396, 407, 380
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy import stats
import json

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def load_and_analyze_data():
    """è¼‰å…¥ä¸¦åˆ†æç‰¹å®šæ–‡ä»¶æ•¸æ“š"""
    
    # è®€å–è©³ç´°æ‘˜è¦CSV
    summary_path = "/Users/albert-mac/Code/GitHub/CPR/output/specific_analysis/detailed_summary.csv"
    df = pd.read_csv(summary_path)
    
    print("ğŸ” ç‰¹å®šæ–‡ä»¶ CPR åˆ†ææ·±åº¦å ±å‘Š")
    print("="*60)
    print(f"åˆ†ææ–‡ä»¶æ•¸é‡: {len(df)}")
    print(f"åˆ†ææ™‚é–“: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. åŸºæœ¬çµ±è¨ˆæ‘˜è¦
    print("ğŸ“Š 1. åŸºæœ¬çµ±è¨ˆæ‘˜è¦")
    print("-"*40)
    
    # ç‰©ç†åƒæ•¸çµ±è¨ˆ
    params = {
        'I_c': 'è‡¨ç•Œé›»æµ (A)',
        'phi_0': 'ç›¸ä½åç§» (rad)', 
        'f': 'ç‰¹å¾µé »ç‡ (Hz)',
        'T': 'æº«åº¦åƒæ•¸ (K)',
        'r': 'é›»é˜» (Î©)',
        'C': 'é›»å®¹ (F)'
    }
    
    for param, name in params.items():
        if param in df.columns:
            values = df[param].dropna()
            if len(values) > 0:
                print(f"\n{name}:")
                print(f"  å¹³å‡å€¼: {values.mean():.4e}")
                print(f"  æ¨™æº–å·®: {values.std():.4e}")
                print(f"  è®Šç•°ä¿‚æ•¸: {(values.std()/values.mean()*100):.2f}%")
                print(f"  ç¯„åœ: [{values.min():.4e}, {values.max():.4e}]")
                print(f"  ä¸­ä½æ•¸: {values.median():.4e}")
                print(f"  å³°åº¦: {stats.kurtosis(values):.3f}")
                print(f"  ååº¦: {stats.skew(values):.3f}")
    
    # 2. æ“¬åˆå“è³ªåˆ†æ
    print("\n\nğŸ¯ 2. æ“¬åˆå“è³ªåˆ†æ")
    print("-"*40)
    
    quality_metrics = {
        'r_squared': 'RÂ²æ±ºå®šä¿‚æ•¸',
        'adj_r_squared': 'èª¿æ•´RÂ²',
        'rmse': 'å‡æ–¹æ ¹èª¤å·®',
        'mae': 'å¹³å‡çµ•å°èª¤å·®'
    }
    
    for metric, name in quality_metrics.items():
        if metric in df.columns:
            values = df[metric].dropna()
            if len(values) > 0:
                print(f"\n{name}:")
                print(f"  å¹³å‡å€¼: {values.mean():.6f}")
                print(f"  æ¨™æº–å·®: {values.std():.6f}")
                print(f"  æœ€ä½³: {values.max():.6f} (æ–‡ä»¶: {df.loc[values.idxmax(), 'dataid']})")
                print(f"  æœ€å·®: {values.min():.6f} (æ–‡ä»¶: {df.loc[values.idxmin(), 'dataid']})")
    
    # 3. æ–‡ä»¶æ’ååˆ†æ
    print("\n\nğŸ† 3. æ–‡ä»¶å“è³ªæ’å")
    print("-"*40)
    
    # æŒ‰RÂ²æ’åº
    df_sorted = df.sort_values('r_squared', ascending=False)
    print("\næŒ‰æ“¬åˆå“è³ª(RÂ²)æ’å:")
    for i, (_, row) in enumerate(df_sorted.iterrows(), 1):
        print(f"  {i}. {row['dataid']}: RÂ² = {row['r_squared']:.6f}")
    
    # 4. åƒæ•¸ç›¸é—œæ€§åˆ†æ
    print("\n\nğŸ”— 4. åƒæ•¸ç›¸é—œæ€§åˆ†æ")
    print("-"*40)
    
    # è¨ˆç®—åƒæ•¸é–“çš„ç›¸é—œä¿‚æ•¸
    param_cols = ['I_c', 'phi_0', 'f', 'T', 'r', 'C']
    correlation_matrix = df[param_cols].corr()
    
    print("\né‡è¦ç›¸é—œæ€§ (|ç›¸é—œä¿‚æ•¸| > 0.5):")
    for i in range(len(param_cols)):
        for j in range(i+1, len(param_cols)):
            corr = correlation_matrix.iloc[i, j]
            if abs(corr) > 0.5:
                print(f"  {param_cols[i]} â†” {param_cols[j]}: {corr:.3f}")
    
    # 5. ç•°å¸¸å€¼æª¢æ¸¬
    print("\n\nâš ï¸ 5. ç•°å¸¸å€¼æª¢æ¸¬")
    print("-"*40)
    
    for param in param_cols:
        if param in df.columns:
            values = df[param].dropna()
            if len(values) > 0:
                Q1 = values.quantile(0.25)
                Q3 = values.quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = values[(values < lower_bound) | (values > upper_bound)]
                if len(outliers) > 0:
                    outlier_files = df[df[param].isin(outliers)]['dataid'].tolist()
                    print(f"\n{param} ç•°å¸¸å€¼:")
                    for file_id, value in zip(outlier_files, outliers):
                        print(f"  {file_id}: {value:.4e}")
    
    # 6. æ€§èƒ½è©•ä¼°
    print("\n\nğŸ“ˆ 6. ç¸½é«”æ€§èƒ½è©•ä¼°")
    print("-"*40)
    
    # è¨ˆç®—ç¶œåˆå¾—åˆ† (åŸºæ–¼å¤šå€‹æŒ‡æ¨™)
    df['performance_score'] = (
        df['r_squared'] * 0.4 +  # RÂ²æ¬Šé‡40%
        df['adj_r_squared'] * 0.3 +  # èª¿æ•´RÂ²æ¬Šé‡30%
        (1 - df['rmse'] / df['rmse'].max()) * 0.2 +  # RMSEæ¬Šé‡20% (åå‘)
        (1 - df['mae'] / df['mae'].max()) * 0.1  # MAEæ¬Šé‡10% (åå‘)
    )
    
    best_performer = df.loc[df['performance_score'].idxmax()]
    worst_performer = df.loc[df['performance_score'].idxmin()]
    
    print(f"\næœ€ä½³æ•´é«”æ€§èƒ½: {best_performer['dataid']}")
    print(f"  ç¶œåˆå¾—åˆ†: {best_performer['performance_score']:.4f}")
    print(f"  RÂ²: {best_performer['r_squared']:.6f}")
    print(f"  RMSE: {best_performer['rmse']:.2e}")
    
    print(f"\næœ€å·®æ•´é«”æ€§èƒ½: {worst_performer['dataid']}")
    print(f"  ç¶œåˆå¾—åˆ†: {worst_performer['performance_score']:.4f}")
    print(f"  RÂ²: {worst_performer['r_squared']:.6f}")
    print(f"  RMSE: {worst_performer['rmse']:.2e}")
    
    # 7. å»ºè­°å’Œçµè«–
    print("\n\nğŸ’¡ 7. åˆ†æçµè«–èˆ‡å»ºè­°")
    print("-"*40)
    
    avg_r2 = df['r_squared'].mean()
    std_r2 = df['r_squared'].std()
    
    print(f"\nâœ… ä¸»è¦ç™¼ç¾:")
    print(f"  â€¢ æ‰€æœ‰9å€‹æ–‡ä»¶éƒ½æˆåŠŸå®Œæˆäº†CPRåˆ†æ")
    print(f"  â€¢ å¹³å‡RÂ²å€¼ç‚º {avg_r2:.4f}ï¼Œè¡¨æ˜æ“¬åˆå“è³ªå„ªç§€")
    print(f"  â€¢ RÂ²æ¨™æº–å·®ç‚º {std_r2:.4f}ï¼Œé¡¯ç¤ºçµæœä¸€è‡´æ€§è‰¯å¥½")
    print(f"  â€¢ æœ€ä½³æ–‡ä»¶ {df.loc[df['r_squared'].idxmax(), 'dataid']} çš„RÂ²é”åˆ° {df['r_squared'].max():.6f}")
    
    print(f"\nğŸ“‹ åƒæ•¸ç‰¹é»:")
    ic_mean = df['I_c'].mean()
    print(f"  â€¢ è‡¨ç•Œé›»æµç¯„åœ: {df['I_c'].min():.2e} - {df['I_c'].max():.2e} A")
    print(f"  â€¢ å¹³å‡è‡¨ç•Œé›»æµ: {ic_mean:.2e} A")
    print(f"  â€¢ é »ç‡é›†ä¸­åœ¨ 121-129 kHz ç¯„åœå…§")
    print(f"  â€¢ æº«åº¦åƒæ•¸åˆ†ä½ˆåœ¨ 0.32-0.80 K ä¹‹é–“")
    
    print(f"\nğŸ”§ å„ªåŒ–å»ºè­°:")
    if std_r2 > 0.01:
        print(f"  â€¢ è€ƒæ…®é€²ä¸€æ­¥å„ªåŒ–æ“¬åˆç®—æ³•ä»¥æé«˜ä¸€è‡´æ€§")
    if df['rmse'].max() > 1e-6:
        print(f"  â€¢ æŸäº›æ–‡ä»¶çš„RMSEè¼ƒé«˜ï¼Œå¯èƒ½éœ€è¦æª¢æŸ¥æ•¸æ“šå“è³ª")
    print(f"  â€¢ æ–‡ä»¶ {df.loc[df['r_squared'].idxmax(), 'dataid']} å¯ä½œç‚ºæœ€ä½³å¯¦è¸åƒè€ƒ")
    
    return df

def create_comprehensive_analysis_plots(df):
    """å‰µå»ºç¶œåˆåˆ†æåœ–è¡¨"""
    
    output_dir = Path("/Users/albert-mac/Code/GitHub/CPR/output/specific_analysis")
    
    # 1. ç›¸é—œæ€§ç†±åœ–
    plt.figure(figsize=(12, 10))
    param_cols = ['I_c', 'phi_0', 'f', 'T', 'r', 'C', 'r_squared', 'rmse']
    correlation_matrix = df[param_cols].corr()
    
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                square=True, fmt='.3f', cbar_kws={'label': 'Correlation Coefficient'})
    plt.title('Parameter Correlation Matrix', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / 'correlation_heatmap.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. æ€§èƒ½é›·é”åœ–
    fig, axes = plt.subplots(2, 2, figsize=(16, 16), subplot_kw=dict(projection='polar'))
    
    top_4_files = df.nlargest(4, 'r_squared')
    
    metrics = ['r_squared', 'adj_r_squared', 'rmse', 'mae']
    metric_labels = ['RÂ²', 'Adj RÂ²', '1-RMSE_norm', '1-MAE_norm']
    
    for idx, (_, row) in enumerate(top_4_files.iterrows()):
        ax = axes[idx//2, idx%2]
        
        # æ­£è¦åŒ–æŒ‡æ¨™ (RMSEå’ŒMAEä½¿ç”¨åå‘æ­£è¦åŒ–)
        values = [
            row['r_squared'],
            row['adj_r_squared'], 
            1 - (row['rmse'] / df['rmse'].max()),  # åå‘æ­£è¦åŒ–
            1 - (row['mae'] / df['mae'].max())     # åå‘æ­£è¦åŒ–
        ]
        
        angles = np.linspace(0, 2*np.pi, len(values), endpoint=False).tolist()
        values += values[:1]  # é–‰åˆåœ–å½¢
        angles += angles[:1]
        
        ax.plot(angles, values, 'o-', linewidth=2, label=row['dataid'])
        ax.fill(angles, values, alpha=0.25)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metric_labels)
        ax.set_ylim(0, 1)
        ax.set_title(f"File: {row['dataid']}", fontweight='bold')
        ax.grid(True)
    
    plt.suptitle('Top 4 Files Performance Radar Chart', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / 'performance_radar.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. åƒæ•¸åˆ†ä½ˆç®±ç·šåœ–
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    param_cols = ['I_c', 'phi_0', 'f', 'T', 'r', 'C']
    param_names = ['Critical Current (A)', 'Phase Offset (rad)', 'Frequency (Hz)', 
                   'Temperature (K)', 'Resistance (Î©)', 'Capacitance (F)']
    
    for i, (param, name) in enumerate(zip(param_cols, param_names)):
        ax = axes[i//3, i%3]
        if param in df.columns:
            df.boxplot(column=param, ax=ax)
            ax.set_title(name, fontweight='bold')
            ax.set_xlabel('')
            
            # æ·»åŠ æ•¸æ“šé»
            y = df[param].dropna()
            x = np.ones(len(y))
            ax.scatter(x, y, alpha=0.6, color='red', s=50)
    
    plt.suptitle('Parameter Distribution Box Plots', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / 'parameter_distributions.png', dpi=300, bbox_inches='tight')
    plt.close()

def main():
    """ä¸»å‡½æ•¸"""
    print("é–‹å§‹ç”Ÿæˆæ·±åº¦åˆ†æå ±å‘Š...")
    
    # è¼‰å…¥ä¸¦åˆ†ææ•¸æ“š
    df = load_and_analyze_data()
    
    # å‰µå»ºç¶œåˆåˆ†æåœ–è¡¨
    create_comprehensive_analysis_plots(df)
    
    print("\n\nğŸ‰ æ·±åº¦åˆ†æå ±å‘Šç”Ÿæˆå®Œæˆï¼")
    print("="*60)
    print("ç”Ÿæˆçš„æ–°æ–‡ä»¶:")
    print("  - correlation_heatmap.png: åƒæ•¸ç›¸é—œæ€§ç†±åœ–")
    print("  - performance_radar.png: æ€§èƒ½é›·é”åœ–")
    print("  - parameter_distributions.png: åƒæ•¸åˆ†ä½ˆç®±ç·šåœ–")

if __name__ == "__main__":
    main()
